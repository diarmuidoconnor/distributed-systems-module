## Dead-Letter Queue.

Suppose we want only JPEG and PNG files processed normally, and all other file types rejected and placed in a dead-letter queue (DLQ) for alternative processing.

![][dlq]

Add the following infrastructure changes to `eda-app-stack.ts`:

- Declare a new queue and set it as the DLQ for the existing one:

```ts
   /  NEW
    const dlq = new sqs.Queue(this, "img-dlq", {
      receiveMessageWaitTime: cdk.Duration.seconds(10),
 });
    // UPDATE
    const queue = new sqs.Queue(this, "img-created-queue", {
      receiveMessageWaitTime: cdk.Duration.seconds(10),
      deadLetterQueue: {
        queue: dlq,
        maxReceiveCount: 1
 }
 });
```

- Add the lambda function to process the messages in the DLQ:

```ts
const rejectedImageFn = new lambdanode.NodejsFunction(
  this,
  "RejectedImagesFn",
  {
    runtime: lambda.Runtime.NODEJS_20_X,
    entry: `${__dirname}/../lambdas/rejectedImages.ts`,
    timeout: cdk.Duration.seconds(15),
    memorySize: 128,
  }
);
```

- Make the new queue (DLQ) an event source:

```ts
const rejectedImageEventSource = new events.SqsEventSource(dlq, {
  batchSize: 5,
  maxBatchingWindow: cdk.Duration.seconds(10),
});
```

- Set the new event source as the trigger for the new lambda function:

```ts
              rejectedImageFn.addEventSource(rejectedImageEventSource);
~~~ts

Create a new file for the lambda function called `lambdas/rejectedImages.ts`, and use the following skeleton code - it just displays the name o the rejected image file:
~~~ts
/* eslint-disable import/extensions, import/no-absolute-path */
import { SQSHandler } from "aws-lambda";

export const handler: SQSHandler = async (event) => {
  console.log("Event ", event);
  for (const record of event.Records) {
    const recordBody = JSON.parse(record.body);
    if (recordBody.Records) {
      for (const s3Message of recordBody.Records) {
        const s3e = s3Message.s3;
        const srcBucket = s3e.bucket.name;
        console.log("Rejected file: ", s3Message.s3.object.key);
 }
 }
 }
};
```

Finally, update the processImages lambda function to throw an exception when an invalid file type is uploaded. The SQS service catches the exception and sends the related message from the main queue to the DLQ.In `lambdas/processImages.ts`, **replace the inner for loop** code with the following:

```ts
for (const s3Message of recordBody.Records) {
  const s3e = s3Message.s3;
  // Object key may have spaces or unicode non-ASCII characters.
  const srcKey = decodeURIComponent(s3e.object.key.replace(/\+/g, " "));
  // Infer the image type from the file suffix.
  const typeMatch = srcKey.match(/\.([^.]*)$/);
  if (!typeMatch) {
    console.log("Could not determine the image type.");
    throw new Error("Could not determine the image type. ");
  }
  // Check that the image type is supported
  const imageType = typeMatch[1].toLowerCase();
  if (imageType != "jpeg" && imageType != "png") {
    throw new Error("Unsupported image type: ${imageType. ");
  }

  await ddbDocClient.send(
    new PutCommand({
      TableName: process.env.TABLE_NAME,
      Item: {
        name: srcKey,
      },
    })
  );
}
```

Deploy these changes to the stack, and try uploading any file whose type extension is neither JPEG nor PNG. Wait a few moments after the upload completes, then check the CloudWatch log stream for the rejected images lambda function to ensure it was triggered. Also, there should not be an item in the database table for the rejected file.

Commit this work:

```bash
$ git add -A
$ git commit -m "Added DLQ for invalid file type uploads"
$ git push origin main
```

[dlq]: ./img/dlq.png
